R Notebook
# load libraries
library(rtweet)
library(ggplot2)
library(dplyr)
library(tidytext)
library(tidyverse)
library(stringr) 
library(tm)
library(quanteda)
library(jsonlite)
library(glue)
library(stringr)
library(e1071)
library(caTools)
library(syuzhet)
library(lubridate)
library(scales)
library(reshape2)
library(caret)
library(rpart)
library(rpart.plot)
library(party)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
vignette("auth", package = "rtweet")
# Extract data via the API
crypto_bitcoin <- search_tweets("#bitcoin", n = 110000, include_rts = FALSE, retryonratelimit = TRUE)
crypto_bitcoin

# Maximum number of tweets returned from a single token is 18,000. To return more than 18,000 tweets, we set retryonratelimit to TRUE.
# Export the table as a csv table
write.csv(crypto_bitcoin,"bitcoin.csv", row.names = FALSE)
Load the data
bitcoin <- read_csv("bitcoin.csv")
Country of the tweeters represented in the dataset
arrange(summarise(group_by(bitcoin, country), Number=n()), desc(Number))
country
<chr>
Number
<int>
NA	115813
United States	285
Turkey	247
India	94
Canada	29
Bangladesh	18
Germany	18
Argentina	17
France	17
United Kingdom	17
1-10 of 69 rows
print( "Most of the countries were the tweeters are located are not identified in the dataset, but we can believe that many countries are represented because we have 67 countries identified")
[1] "Most of the countries were the tweeters are located are not identified in the dataset, but we can believe that many countries are represented because we have 67 countries identified"
#Visualization of the top 10 countries found in the dataset
Countries <-head(arrange(summarise(group_by(bitcoin , country_code), Number=n()), desc(Number)), 11)
ggplot(Countries ,aes(x= country_code, y= Number )) +  
  labs(title=" The top 10 countries indentified ",x="Country",y ="Number of tweets")+
  geom_bar(stat="identity", fill="blue") + geom_text(aes(label= Number, vjust=-0.3))


# cleaning up the data
bitcoin1 <- bitcoin %>%
    select_if(~ !any(is.na(.)))
head(bitcoin1)
user_id
<dbl>
status_id
<dbl>
created_at
<dbl>
screen_name
<chr>
1575636434	1.46709e+18	1638615561	DragonBallTee	
1575636434	1.46705e+18	1638607200	DragonBallTee	
1575636434	1.46707e+18	1638611613	DragonBallTee	
1575636434	1.46707e+18	1638611250	DragonBallTee	
1575636434	1.46705e+18	1638606109	DragonBallTee	
1575636434	1.46706e+18	1638610250	DragonBallTee	
6 rows | 1-4 of 26 columns
Considering the languages
#Group by language
arrange(summarise(group_by(bitcoin1, lang), Number=n()), desc(Number))
lang
<chr>
Number
<int>
en	76819
tr	13950
und	9261
in	3376
es	3052
fr	1777
ja	1327
de	1106
pt	854
ht	729
1-10 of 50 rows
print( "We have 50 languages represented in the dataset")
[1] "We have 50 languages represented in the dataset"
# visualization of the languages that figure in the dataset
Languages <-head(arrange(summarise(group_by(bitcoin1 , lang), Number=n()), desc(Number)), 5)
ggplot(Languages ,aes(x= lang, y= Number )) +  
  labs(title=" The top 5 languages indentified ",x="Language",y ="Number of tweets")+
  geom_bar(stat="identity", fill="grey") + geom_text(aes(label= Number, vjust=-0.3))


# Visualization of the languages and time of the tweets
ggplot(data = bitcoin1, mapping = aes(x = created_at, y =lang)) + 
  geom_point(mapping = aes(color = lang)) + labs(title = "Tweets by languages and time " ,
x="Time", y="Languages")


#Visualization of the time of creation of an account and time of creation of a tweet
ggplot(bitcoin1, mapping = aes(account_created_at/10000, created_at/10000)) +
  geom_point(mapping = aes(color = lang)) +
  labs(title = "Bitcoin Tweets",
       x = "account_created_at", y = "created_at")


Considering the number of tweeters
# Different tweeters represented in the dataset
arrange(summarise(group_by(bitcoin1,screen_name), Number=n()), desc(Number))
screen_name
<chr>
Number
<int>
BTC_Whale_Alert	2997
DragonBallTee	2285
brettmurphynet	2169
bmurphypointman	1986
MerveKs07715294	622
ultimobtc	459
WatchinWhales	416
Iran_Shiba	405
Bot11031	383
Bot4DTU	383
...
1-10 of 41,344 rows
print( "We have 41344 different tweeters")
[1] "We have 41344 different tweeters"
#Visualization of the top 5 tweeters with more tweets 
Tweeters <-head(arrange(summarise(group_by(bitcoin1 , screen_name), Number=n()), desc(Number)), 5)
ggplot(Tweeters ,aes(x= screen_name, y= Number )) +  
  labs(title=" The top 5 indentified tweeters ",x="Tweeters",y ="Number of tweets")+
  geom_bar(stat="identity", fill="lightblue") + geom_text(aes(label= Number, vjust=-0.3))


Considering the number of retweets
#Visualization of the top 10 tweeters whose post have been retweeted more
Retweets <- head(arrange (group_by(bitcoin1,retweet_count), desc(retweet_count)),50)
Retweets
user_id
<dbl>
status_id
<dbl>
created_at
<dbl>
screen_name
<chr>
1.151150e+18	1.46674e+18	1638533967	airdropinspect	
1.173430e+18	1.46656e+18	1638491215	AirdropStario	
1.151150e+18	1.46680e+18	1638546239	airdropinspect	
1.151150e+18	1.46653e+18	1638482239	airdropinspect	
1.151150e+18	1.46684e+18	1638556919	airdropinspect	
2.073651e+07	1.46700e+18	1638595178	nayibbukele	
1.173430e+18	1.46685e+18	1638560295	AirdropStario	
1.173430e+18	1.46691e+18	1638573471	AirdropStario	
1.173430e+18	1.46672e+18	1638527309	AirdropStario	
1.151150e+18	1.46668e+18	1638518949	airdropinspect	
1-10 of 50 rows | 1-4 of 26 columns
#Visualization
ggplot(Retweets,aes(x= screen_name, y=retweet_count)) +  
  labs(title=" Tweeters with more retweet ",x="Tweeters",y ="Number of retweets")+
  geom_bar(stat="identity", fill="blue")+ coord_flip()


print("the 3 tweeters account with more retweets are : airdropinspect , AirdropStario and nayibbukele ")
[1] "the 3 tweeters account with more retweets are : airdropinspect , AirdropStario and nayibbukele "
Considering number of followers
Followers <- head(arrange(summarise(group_by(bitcoin1, screen_name), followers_count), desc(followers_count)),100)
`summarise()` has grouped output by 'screen_name'. You can override using the `.groups` argument.
Followers
screen_name
<chr>
followers_count
<dbl>
htTweets	8306896
binance	6462133
Hurriyet	4295752
EconomicTimes	4076908
Thairath_News	4044498
Bitcoin	3910518
Bitcoin	3910041
Bitcoin	3910041
justinsuntron	3267613
justinsuntron	3267613
...
1-10 of 100 rows
#Visualization
ggplot(head(Followers,50) ,aes(x=screen_name, y = followers_count )) +  
  labs(title=" Tweeters with more followers ",x="Tweeters",y ="Number of followers")+
  geom_bar(stat="identity", fill="blue")+ coord_flip()


print("The top 3 tweeters account with more followers are : CoinDesk, BTCTN and BitcoinMagazine")
[1] "The top 3 tweeters account with more followers are : CoinDesk, BTCTN and BitcoinMagazine"
Text Analysis
#Count Bitcoin(s) and bitcoin(s) occurances
BitcoinCount<-sum(str_detect(bitcoin1$text, "Bitcoin"))
cat("Number of tweets with 'Bitcoin':", BitcoinCount, "\n")
Number of tweets with 'Bitcoin': 80992 
bitcoinCount <-sum (str_detect(bitcoin1$text, "bitcoin")) 
cat("Number of tweets with 'bitcoin':", bitcoinCount, "\n")
Number of tweets with 'bitcoin': 42562 
BitcoinsCount<-sum(str_detect(bitcoin1$text, "Bitcoins"))
cat("Number of tweets with 'Bitcoins':", BitcoinsCount, "\n")
Number of tweets with 'Bitcoins': 377 
bitcoinsCount<-sum(str_detect(bitcoin1$text, "bitcoins"))
cat("Number of tweets with 'bitcoins':", bitcoinsCount, "\n")
Number of tweets with 'bitcoins': 404 
cryptoCount<-sum(str_detect(bitcoin1$text, "crypto"))
cat("Number of tweets with 'crypto':", cryptoCount, "\n")
Number of tweets with 'crypto': 28476 
Pie Chart
mentions <- c(42562, 80992, 28476, 781)
lbls <- c("bitcoin", "Bitcoin", "crypto", "Bitcoin(s)")
pie(mentions, labels = lbls,col=rainbow(length(lbls)), main="Mentions of Bitcoin(s) and crypto")


Count Bitcoin(s) and bitcoin(s)
BitcoinOrbitcoin<-sum(str_detect(bitcoin1$text,"bitcoin|Bitcoin|bitcoins|Bitcoins"))
cat("Number of tweets with 'bitcoin(s)' or Bitcoin(s):" , BitcoinOrbitcoin, "\n")
Number of tweets with 'bitcoin(s)' or Bitcoin(s): 115196 
Number of hashtags
hashtags= sum(str_detect(bitcoin1$text,"#")) 
cat("Number of hashtags:",hashtags, "\n")
Number of hashtags: 116793 
Number of mentions
mentions = sum(str_detect(bitcoin1$text,"@"))
cat("Number of mentions:",mentions)
Number of mentions: 38081
How many times was #Giveaway mentioned
sum(str_detect(bitcoin1$text,"#Giveaway"))
[1] 776
print("Giveaway was mentionned 776 times")
[1] "Giveaway was mentionned 776 times"
Corpus Analysis(Term Frequency)
#You need to use Vector Source before using Corpus
tweetCorpus <- Corpus(VectorSource(bitcoin1$text))
#Term Document Matrix
tweetTDM <- TermDocumentMatrix(tweetCorpus)
inspect(tweetTDM)
<<TermDocumentMatrix (terms: 297781, documents: 116798)>>
Non-/sparse entries: 2223670/34778001568
Sparsity           : 100%
Maximal term length: 239
Weighting          : term frequency (tf)
Sample             :
                 Docs
Terms             112043 112045 112046 112048 112049 112050 112051 112052 112058
  #bitcoin             1      1      1      1      1      1      1      1      1
  #btc                 0      0      0      0      0      0      0      0      0
  #crypto              0      0      0      0      0      0      0      0      0
  #cryptocurrency      0      0      0      0      0      0      0      0      0
  #eth                 0      0      0      0      0      0      0      0      0
  and                  0      0      0      0      0      0      0      0      0
  for                  0      0      0      0      0      0      0      0      0
  project              0      0      0      0      0      0      0      0      0
  the                  0      0      0      0      0      0      0      0      0
  this                 0      0      0      0      0      0      0      0      0
                 Docs
Terms             114027
  #bitcoin             1
  #btc                 0
  #crypto              0
  #cryptocurrency      0
  #eth                 0
  and                  1
  for                  1
  project              0
  the                  2
  this                 0
Document feature Matrix
tweetDFM<-dfm(bitcoin1$text, remove_punct=TRUE, remove=stopwords("english"))
'dfm.character()' is deprecated. Use 'tokens()' first.'...' should not be used for tokens() arguments; use 'tokens()' first.'remove' is deprecated; use dfm_remove() instead
topfeatures(tweetDFM)
       #bitcoin               $            #btc         #crypto         project 
         119742           82392           26273           25072           16150 
#cryptocurrency              ðŸš€            #eth             btc       #ethereum 
          15329           15255           13283           12236           11668 
tweetDFM<-dfm(tweetTDM$text, remove_punct=TRUE, remove=stopwords("english"))
tweetDFM <- as.matrix(head(tweetDFM, 5000))
sent <- iconv(bitcoin1$text)
sentiments<- head(sent, 10000)
#Obtain sentiment scores
s <- get_nrc_sentiment(sentiments)
head(s)
 
 
anger
<dbl>
anticipation
<dbl>
disgust
<dbl>
fear
<dbl>
joy
<dbl>
sadness
<dbl>
surprise
<dbl>
trust
<dbl>
negative
<dbl>
1	0	0	0	0	0	0	0	0	0	
2	0	0	0	0	0	0	0	0	0	
3	0	0	0	0	0	0	0	0	0	
4	0	0	0	0	0	0	0	0	0	
5	0	0	0	0	0	0	0	0	0	
6	0	0	0	0	0	0	0	0	0	
6 rows | 1-10 of 10 columns
barplot(colSums(s),
        las = 2,
        col = rainbow(10),
        ylab = 'Count',
        main = 'Sentiment Scores Tweets')


Classification Models (Naive Bayes, Decision Trees, Logistic Regression)
Naive Bayes
#Remove unnecessary columns 
bitcoin2 <- bitcoin1[-c(1,2,3,5,6,8,9,10,12,14,15,16,17,26,24)]
head(bitcoin2)
screen_name
<chr>
display_text_width
<dbl>
retweet_count
<dbl>
lang
<chr>
protected
<lgl>
followers_count
<dbl>
friends_count
<dbl>
DragonBallTee	208	0	in	FALSE	624	2382	
DragonBallTee	191	2	in	FALSE	624	2382	
DragonBallTee	191	1	in	FALSE	624	2382	
DragonBallTee	191	0	in	FALSE	624	2382	
DragonBallTee	191	0	in	FALSE	624	2382	
DragonBallTee	191	1	in	FALSE	624	2382	
6 rows | 1-7 of 11 columns
# Test and Train the data
set.seed(123)
sample <- sample.split(bitcoin2$retweet_count, SplitRatio = .75)
train <- subset(bitcoin2, sample == TRUE)
test <- subset(bitcoin2, sample == FALSE)
# Build the naiveBayes classifier
nb_model <- naiveBayes(retweet_count~., data = train)
# Make prediction with testing set
nb_prediction <- predict(nb_model, test, type = "class")
# Confusion Matrix3
table(test$retweet_count, nb_prediction, dnn=c("Actual", "Prediction"))
      Prediction
Actual     0     1     2     3     4     5     6     7     8     9    10    11
   0   10355    13     5     0     0     0     1     3     2     8     0     1
   1    1168     5     1     0     0     0     0     1     0     6     0     0
   2     302     0     1     0     0     0     0     2     0     1     0     0
      Prediction
Actual    12    13    14    15    16    17    18    19    20    21    22    23
   0       0     2     0     1     0   357     1     1     0     0     0     0
   1       0     0     0     0     0   116     1     0     0     0     0     0
   2       0     0     0     0     0    16     0     0     0     0     0     0
      Prediction
Actual    24    25    26    27    28    29    30    31    32    33    34    35
   0       0     2     2     6     1     0     0     0     1     2     2     0
   1       0     0     0     3     1     0     0     0     0     1     1     0
   2       0     0     0     2     0     0     0     0     0     0     1     0
      Prediction
Actual    36    37    38    39    40    41    42    43    44    45    46    47
   0       0     0    11     0     1     0     0     0     1     0     0     0
   1       0     0     0     0     0     0     0     0     0     0     0     0
   2       0     0     0     0     0     0     0     0     0     0     0     0
      Prediction
Actual    48    49    50    51    52    53    54    55    56    57    58    59
   0       0     0     0     0     1     0     0     0     2     0     0    18
   1       0     0     0     0     0     0     0     0     0     0     0     2
   2       0     0     0     0     0     0     0     0     0     0     0     2
      Prediction
Actual    60    61    62    63    64    65    66    67    68    69    70    71
   0       0     0     0     0     0     0     0   800   392     0     0     0
   1       0     0     0     0     0     0     0   100    58     0     0     0
   2       0     0     0     0     0     0     0    31    22     0     0     0
      Prediction
Actual    72    73    74    75    76    77    78    79    80    81    82    83
   0       0     0     0   186     0     0     2     0     5     0     2     0
   1       0     0     0    30     0     0     0     0     1     0     1     0
   2       0     0     0    11     0     0     0     0     2     0     1     0
      Prediction
Actual    84    85    86    87    88    89    90    91    92    93    94    95
   0       0     2     0     1    80   154     1     6     3     0   201     0
   1       0     0     0     0    10     9     0     1     0     0    38     0
   2       0     0     0     0     5     2     0     2     1     0     9     0
      Prediction
Actual    96    97    98    99   100   101   102   103   104   105   106   107
   0       5     2  1020     1     1     1     0     0     1     0     0     0
   1       2     0   115     0     1     1     0     0     1     0     0     0
   2       1     0    38     1     0     1     0     0     0     0     0     0
      Prediction
Actual   108   109   110   111   113   114   115   117   118   120   121   122
   0       0     1     0    21     0     0     0     4     0     0     0     0
   1       0     0     0     8     2     0     0     1     0     0     0     0
   2       0     0     0     0     0     0     0     0     0     0     0     0
      Prediction
Actual   125   126   127   128   129   130   134   136   137   138   139   141
   0       0     0     1     0     0     0   343     0     0     3     0     0
   1       0     0     0     0     0     0    33     0     0     1     0     0
   2       0     0     0     0     0     0    10     0     0     0     0     0
      Prediction
Actual   144   145   146   147   148   149   150   151   152   154   155   156
   0      19     0     0     0     0     0    51     1     0   182     3     0
   1       6     0     0     0     0     0     6     3     0    18     4     0
   2       4     0     0     0     0     0     2     1     0     9     4     0
      Prediction
Actual   157   158   159   161   162   163   166   168   169   171   173   175
   0       0     0     0     0     0     0     0     0     0     0     0     0
   1       0     0     0     0     0     0     0     0     0     0     1     0
   2       0     0     0     0     0     0     1     0     0     0     0     0
      Prediction
Actual   179   183   184   185   186   188   191   192   195   196   197   199
   0     723     0    87     0     0     0     0     0     0     0   730     0
   1      75     0    10     0     0     0     0     0     0     0    88     0
   2      16     0     3     0     0     0     0     0     0     0    21     0
      Prediction
Actual   200   201   203   208   209   210   211   215   218   220   222   224
   0       0     0     0     0  1327     0     0  2622     0     0     0     0
   1       0     0     0     0   136     0     0   388     0     0     0     0
   2       0     0     0     0    30     0     0    83     0     0     0     0
      Prediction
Actual   225   227   230   231   232   234   236   241   244   245   247   249
   0       0     0  2195     0  2027     0     0     0     0     0     0     1
   1       0     0   237     0   174     0     0     0     0     0     0     0
   2       0     0    48     0    38     0     0     0     0     0     0     0
      Prediction
Actual   250   257   263   266   268   273   275   276   289   290   291   302
   0       0     0     0     5     0     0     0     0     0     0     0    20
   1       0     0     0     0     0     0     0     0     0     0     0     5
   2       0     0     0     2     0     0     0     0     0     0     0     1
      Prediction
Actual   308   310   311   321   322   329   335   337   353   368   385   388
   0       0     0     0     0     0     0     0     0     0     0     0     0
   1       0     0     0     0     0     0     0     0     0     0     0     0
   2       0     0     0     0     0     0     0     0     0     0     0     0
      Prediction
Actual   390   391   394   399   405   414   420   428   459   460   462   464
   0       0     0     0     0     0     0     0     0     0     0     0     0
   1       0     0     0     0     0     0     0     0     0     0     0     0
   2       0     0     0     0     0     0     0     0     0     0     0     0
      Prediction
Actual   470   472   473   514   519   525   528   538   543   546   562   579
   0       0     0     4     0     0     0     0     0     0     0     0     0
   1       0     0     0     0     0     0     0     0     0     0     0     0
   2       0     0     2     0     0     0     0     0     0     0     0     0
      Prediction
Actual   624   686   699   774   775   778   779   789   815   848   851   898
   0       0     0     0     0     0     0     0     0     0     0     0     0
   1       0     0     0     0     0     0     0     0     0     0     0     0
   2       0     0     0     0     0     0     0     0     0     0     0     0
      Prediction
Actual   945   956   984  1080  1165  1216  1237  1254  1370  1405  1408  1418
   0       0     0     0     0     0     0     0     0     0     0     0     0
   1       0     0     0     0     0     0     0     0     0     0     0     0
   2       0     0     0     0     0     0     0     0     0     0     0     0
      Prediction
Actual  1449  1571  1746  1784  2415  2838  3205  3930  4432  5627  5728  6267
   0       0     0     0     0     0     0     0     0     0     0     0     0
   1       0     0     0     0     0     0     0     0     0     0     0     0
   2       0     0     0     0     0     0     0     0     0     0     0     0
      Prediction
Actual  6390  6916  7871 10648 13323
   0       0     0     0     0     0
   1       0     0     0     0     0
   2       0     0     0     0     0
 [ reached getOption("max.print") -- omitted 109 rows ]
# Output results
test$Prediction <- nb_prediction
# Accuracy is the overall success rate of the model
# Extract  TP + TN 
tpTN <-  nrow(test)
# Get the size of the testing set (TP + TN + FP + FN)
testsize <- nrow(test)
# Calculate accuracy
accuracy <- tpTN/testsize
cat("Naive Bayes Classifier Accuracy:", accuracy)
Naive Bayes Classifier Accuracy: 1
#LaPlace 1 
# Build the Naive Beyes classifier
laplace_model <- naiveBayes(retweet_count~., data = train, laplace = 1)
laplace_prediction <- predict(laplace_model, test, type = "class")
# Get TP + TF
laplace_results <- data_frame(Actual = test$retweet_count, Prediction = laplace_prediction)
`data_frame()` was deprecated in tibble 1.1.0.
Please use `tibble()` instead.
accurateRows <- subset(laplace_results, Actual == Prediction)
# Calculate Accuracy
laplace_accuracy <-nrow(accurateRows) / nrow(test)
cat("LaPlace1 Accuracy:", laplace_accuracy)
LaPlace1 Accuracy: 0.07107087
#LaPlace 3 
# Build the Naive Beyes classifier
laplace_model <- naiveBayes(retweet_count~., data = train, laplace = 3)
laplace_prediction <- predict(laplace_model, test, type = "class")
# Get TP + TF
laplace_results <- data_frame(Actual = test$retweet_count, Prediction = laplace_prediction)
accurateRows <- subset(laplace_results, Actual == Prediction)
# Calculate Accuracy
laplace_accuracy <-nrow(accurateRows) / nrow(test)
cat("LaPlace of 3 Accuracy:", laplace_accuracy)
LaPlace of 3 Accuracy: 0.0615696
Decision Trees
Build CTree
head(bitcoin2)
screen_name
<chr>
display_text_width
<dbl>
retweet_count
<dbl>
lang
<chr>
protected
<lgl>
followers_count
<dbl>
friends_count
<dbl>
DragonBallTee	208	0	in	FALSE	624	2382	
DragonBallTee	191	2	in	FALSE	624	2382	
DragonBallTee	191	1	in	FALSE	624	2382	
DragonBallTee	191	0	in	FALSE	624	2382	
DragonBallTee	191	0	in	FALSE	624	2382	
DragonBallTee	191	1	in	FALSE	624	2382	
6 rows | 1-7 of 11 columns
#Remove unnecessary columns 
bitcoin3 <- head(bitcoin2[-c(1,2,4,8)],10000)
head(bitcoin3)
retweet_count
<dbl>
protected
<lgl>
followers_count
<dbl>
friends_count
<dbl>
statuses_count
<dbl>
favourites_count
<dbl>
verified
<lgl>
0	FALSE	624	2382	61747	123	FALSE
2	FALSE	624	2382	61747	123	FALSE
1	FALSE	624	2382	61747	123	FALSE
0	FALSE	624	2382	61747	123	FALSE
0	FALSE	624	2382	61747	123	FALSE
1	FALSE	624	2382	61747	123	FALSE
6 rows
# Test and Train the data
set.seed(123)
sample <- sample.split(bitcoin3$verified, SplitRatio = .75)
train <- subset(bitcoin3, sample == TRUE)
test <- subset(bitcoin3, sample == FALSE)
# Create the tree
ctreemodel <- ctree(retweet_count ~., data = train)
plot(ctreemodel)


# Predict CTree
pred.ctree <- predict(ctreemodel, newdata = test, test = "response")
## Confusion Matrix
pred.ctree <- predict(ctreemodel, newdata = test, test = "response")
ctree.Matrix <- table(test$retweet_count, pred.ctree, dnn = c("Actual", "Prediction"))
ctree.Matrix
      Prediction
Actual 0.202020202020202 0.264769923065757    1 1.22058823529412 2.43243243243243
   0                  51              2074    5               15                4
   1                   9               160    3                7                3
   2                   1                38    0                1                1
   3                   0                11    0                0                0
   4                   0                 4    0                1                0
   5                   0                 5    0                0                0
   6                   0                 4    0                0                0
   7                   0                 5    0                0                0
   8                   0                 3    0                0                0
   9                   0                 1    0                0                0
   10                  0                 1    0                0                0
   11                  0                 1    0                0                0
   12                  0                 1    0                0                0
   14                  0                 1    0                0                0
   18                  0                 1    0                0                0
   19                  0                 0    0                0                0
   22                  0                 0    0                0                0
   24                  0                 0    0                0                0
   26                  0                 1    0                0                0
   31                  0                 0    0                0                0
   33                  0                 1    0                0                0
   86                  0                 0    0                0                0
   95                  0                 0    0                0                0
   579                 0                 0    0                0                0
      Prediction
Actual 3.58260869565217 5.92105263157895 6.42857142857143 17.6333333333333 22.9
   0                 12               23                1                3    0
   1                  4                6                0                1    1
   2                  3                1                0                0    0
   3                  2                2                0                0    0
   4                  1                0                1                0    0
   5                  7                0                0                0    0
   6                  0                0                0                0    0
   7                  1                0                1                0    0
   8                  0                0                0                1    0
   9                  2                0                0                0    1
   10                 0                0                0                0    0
   11                 0                0                0                1    0
   12                 0                0                0                0    0
   14                 0                0                0                0    0
   18                 0                1                0                0    0
   19                 1                1                0                0    0
   22                 0                0                0                1    0
   24                 0                0                0                1    0
   26                 0                0                0                0    0
   31                 0                0                0                1    0
   33                 0                0                0                1    0
   86                 1                0                0                0    0
   95                 1                0                0                0    0
   579                0                0                0                0    0
      Prediction
Actual 444.555555555556
   0                  1
   1                  0
   2                  0
   3                  1
   4                  0
   5                  0
   6                  0
   7                  0
   8                  0
   9                  0
   10                 0
   11                 0
   12                 0
   14                 0
   18                 0
   19                 0
   22                 0
   24                 0
   26                 0
   31                 0
   33                 0
   86                 0
   95                 0
   579                1
## Accuracy
accuracy <- sum(diag(ctree.Matrix) / sum(ctree.Matrix))
cat("The accuracy of the Decision tree is :",accuracy)
The accuracy of the Decision tree is : 0.0884
Logistic regression
Build Model
#Remove unnecessary columns 
bitcoin4 <- head(bitcoin3[-c(2)],10000)
bitcoin4<-head(bitcoin4,10000)
# Test and Train the data
set.seed(123)
sample <- sample.split(bitcoin4$followers_count, SplitRatio = .75)
train <- subset(bitcoin4, sample == TRUE)
test <- subset(bitcoin4, sample == FALSE)
lgModel <- glm(verified ~., data = train,family = binomial)
glm.fit: fitted probabilities numerically 0 or 1 occurred
plot(lgModel)








Make prediction
Prediction <- predict(lgModel, newdata = test, test = "response")
Prediction
        1         2         3         4         5         6         7         8 
-6.047055 -5.976193 -5.976193 -5.976193 -5.976193 -5.976193 -5.976193 -6.011624 
        9        10        11        12        13        14        15        16 
-5.976193 -5.976193 -6.011624 -5.976193 -5.976193 -5.976193 -6.011624 -5.976193 
       17        18        19        20        21        22        23        24 
-5.976193 -5.976193 -5.976193 -5.976193 -5.976193 -6.011624 -6.047055 -6.011624 
       25        26        27        28        29        30        31        32 
-5.976193 -5.976193 -6.011624 -5.976193 -5.976193 -5.976193 -5.976193 -5.976193 
       33        34        35        36        37        38        39        40 
-5.976193 -5.976193 -6.047055 -5.976193 -5.976193 -5.976193 -6.011624 -6.011624 
       41        42        43        44        45        46        47        48 
-5.957343 -5.957343 -5.957343 -5.957343 -5.957343 -5.957343 -5.957343 -5.957343 
       49        50        51        52        53        54        55        56 
-5.957343 -5.956224 -5.953161 -5.955280 -3.520384 -5.948878 -5.953365 -5.955333 
       57        58        59        60        61        62        63        64 
-5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 
       65        66        67        68        69        70        71        72 
-5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 
       73        74        75        76        77        78        79        80 
-5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 -5.945397 
       81        82        83        84        85        86        87        88 
-5.945397 -5.945397 -5.957886 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 
       89        90        91        92        93        94        95        96 
-5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 
       97        98        99       100       101       102       103       104 
-5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 
      105       106       107       108       109       110       111       112 
-5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 
      113       114       115       116       117       118       119       120 
-5.971870 -6.007301 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 -5.971870 
      121       122       123       124       125       126       127       128 
-5.971870 -5.971870 -5.971870 -5.938183 -5.938183 -5.938183 -5.938183 -5.876068 
      129       130       131       132       133       134       135       136 
-5.946474 -5.955646 -5.948478 -5.959932 -5.919060 -5.919060 -5.919060 -5.954440 
      137       138       139       140       141       142       143       144 
-5.955407 -5.955407 -5.940817 -5.940817 -5.952209 -5.952209 -5.854406 -5.941477 
      145       146       147       148       149       150       151       152 
-5.954679 -5.954679 -5.777068 -5.777068 -5.777068 -5.938608 -5.938608 -5.961203 
      153       154       155       156       157       158       159       160 
-5.923334 -5.937774 -5.953332 -5.939656 -5.932529 -5.953834 -5.835813 -5.835813 
      161       162       163       164       165       166       167       168 
-5.835813 -5.835813 -5.957197 -6.156358 -6.156358 -6.156358 -6.156358 -6.191789 
      169       170       171       172       173       174       175       176 
-6.191789 -6.156358 -6.191789 -6.156358 -5.954493 -5.963556 -5.963556 -5.963556 
      177       178       179       180       181       182       183       184 
-5.845613 -5.970379 -5.970379 -5.970379 -5.970379 -5.970379 -5.970379 -5.970379 
      185       186       187       188       189       190       191       192 
-5.970379 -5.768296 -5.957923 -5.873116 -5.873116 -5.956479 -5.943629 -5.957284 
      193       194       195       196       197       198       199       200 
-5.944658 -5.953682 -5.957822 -4.531670 -5.956550 -6.669091 -6.669091 -6.669091 
      201       202       203       204       205       206       207       208 
-6.669091 -6.669091 -6.669091 -6.669091 -6.669091 -6.669091 -6.669091 -6.669091 
      209       210       211       212       213       214       215       216 
-6.669091 -6.669091 -6.704522 -6.669091 -6.704522 -6.669091 -6.669091 -6.669091 
      217       218       219       220       221       222       223       224 
-6.669091 -6.739953 -6.669091 -6.669091 -6.669091 -6.669091 -6.704522 -6.669091 
      225       226       227       228       229       230       231       232 
-6.669091 -6.669091 -6.704522 -6.669091 -6.704522 -6.669091 -6.669091 -6.669091 
      233       234       235       236       237       238       239       240 
-6.669091 -6.669091 -6.669091 -6.704522 -6.669091 -6.669091 -6.669091 -6.669091 
      241       242       243       244       245       246       247       248 
-6.669091 -6.669091 -6.669091 -6.669091 -6.704522 -6.669091 -6.669091 -6.669091 
      249       250       251       252       253       254       255       256 
-6.704522 -6.669091 -6.669091 -6.669091 -6.669091 -6.669091 -6.669091 -6.704522 
      257       258       259       260       261       262       263       264 
-6.704522 -6.704522 -6.704522 -6.669091 -6.669091 -6.212741 -6.212741 -6.212741 
      265       266       267       268       269       270       271       272 
-6.248171 -6.212741 -6.212741 -6.212741 -6.212741 -6.248171 -6.212741 -6.212741 
      273       274       275       276       277       278       279       280 
-6.212741 -6.212741 -6.212741 -6.248171 -6.212741 -6.212741 -6.212741 -6.212741 
      281       282       283       284       285       286       287       288 
-6.212741 -6.248171 -6.212741 -6.248171 -6.212741 -6.212741 -6.212741 -6.248171 
      289       290       291       292       293       294       295       296 
-6.212741 -6.283602 -6.248171 -6.248171 -6.212741 -6.212741 -6.212741 -6.212741 
      297       298       299       300       301       302       303       304 
-6.212741 -6.212741 -6.212741 -6.248171 -6.212741 -6.212741 -6.212741 -6.212741 
      305       306       307       308       309       310       311       312 
-6.212741 -6.248171 -6.212741 -6.212741 -6.212741 -6.248171 -6.212741 -6.212741 
      313       314       315       316       317       318       319       320 
-6.248171 -6.212741 -6.212741 -5.943601 -5.954502 -5.953434 -5.953434 -5.953434 
      321       322       323       324       325       326       327       328 
-5.953434 -5.953434 -5.953434 -5.952535 -5.952535 -5.952249 -5.954865 -5.957103 
      329       330       331       332       333       334       335       336 
-5.910315 -5.916080 -5.780243 -5.992745 -5.992745 -5.992745 -5.992745 -5.992745 
      337       338       339       340       341       342       343       344 
-5.992745 -5.992745 -5.992745 -5.992745 -5.992745 -5.992745 -5.992745 -6.993258 
      345       346       347       348       349       350       351       352 
-6.816105 -5.967175 -5.967175 -5.967175 -5.967175 -5.967175 -5.967175 -5.967175 
      353       354       355       356       357       358       359       360 
-5.967175 -5.967175 -5.914817 -5.931089 -5.540960 -5.943461 -5.943461 -5.957457 
      361       362       363       364       365       366       367       368 
-5.970846 -5.970846 -5.970846 -5.970846 -5.970846 -5.970846 -5.970846 -5.970846 
      369       370       371       372       373       374       375       376 
-5.952598 -5.957042 -5.957042 -5.917588 -5.917588 -5.957967 -5.953040 -5.954774 
      377       378       379       380       381       382       383       384 
-5.957866 -5.964072 -5.964072 -5.964072 -5.940716 -5.938187 -5.971093 -5.971093 
      385       386       387       388       389       390       391       392 
-5.971093 -5.971093 -5.971093 -5.971093 -5.971093 -5.971093 -5.916130 -5.920697 
      393       394       395       396       397       398       399       400 
-5.917505 -5.947474 -5.918510 -5.946356 -5.944965 -5.957169 -5.949520 -5.989460 
      401       402       403       404       405       406       407       408 
-5.993092 -5.946717 -5.958024 -5.930424 -5.804872 -5.960584 -5.960584 -5.960584 
      409       410       411       412       413       414       415       416 
-5.960584 -5.960584 -5.960584 -5.960584 -5.960584 -5.960584 -5.960584 -5.960584 
      417       418       419       420       421       422       423       424 
-5.957939 -5.956543 -5.956543 -5.943186 -5.956894 -5.954326 -6.076620 -5.945223 
      425       426       427       428       429       430       431       432 
-5.935166 -5.698665 -5.916264 -5.959377 -5.959377 -5.959377 -5.959377 -5.959377 
      433       434       435       436       437       438       439       440 
-5.959377 -5.959377 -5.959377 -5.959377 -5.959377 -5.959377 -5.951877 -5.954175 
      441       442       443       444       445       446       447       448 
-6.088131 -6.088131 -6.158992 -6.088131 -5.958105 -5.958105 -5.958105 -5.958105 
      449       450       451       452       453       454       455       456 
-5.945484 -5.945484 -5.980229 -5.980229 -5.980229 -5.946465 -5.954878 -5.955489 
      457       458       459       460       461       462       463       464 
-5.946779 -5.962537 -5.962537 -5.997968 -5.957671 -5.957671 -5.957671 -5.957671 
      465       466       467       468       469       470       471       472 
-5.957671 -5.947227 -5.830449 -5.957922 -5.958030 -5.957630 -5.956683 -6.004125 
      473       474       475       476       477       478       479       480 
-6.004125 -6.004125 -6.004125 -5.954914 -5.957891 -5.948822 -5.846376 -5.846376 
      481       482       483       484       485       486       487       488 
-5.977068 -5.977068 -5.977068 -5.961855 -5.961855 -5.961855 -5.943226 -5.736721 
      489       490       491       492       493       494       495       496 
-5.807582 -5.772152 -5.957781 -5.953890 -5.953890 -5.986547 -5.946206 -5.946206 
      497       498       499       500       501       502       503       504 
-5.963320 -5.963320 -5.916224 -5.937712 -5.957374 -5.957374 -5.957374 -5.957374 
      505       506       507       508       509       510       511       512 
-5.957374 -5.957374 -5.932323 -5.987925 -5.987925 -5.983540 -5.983540 -5.983540 
      513       514       515       516       517       518       519       520 
-5.983540 -5.983540 -5.983540 -5.796559 -5.927382 -5.956374 -5.991804 -4.982742 
      521       522       523       524       525       526       527       528 
-5.968656 -5.968656 -5.956608 -5.982440 -5.982440 -5.957498 -5.957498 -5.957498 
      529       530       531       532       533       534       535       536 
-5.957498 -5.957498 -5.957498 -5.957498 -5.957498 -5.957498 -5.957498 -5.957498 
      537       538       539       540       541       542       543       544 
-5.953509 -5.953509 -5.957063 -5.956146 -5.963669 -5.952731 -5.952731 -5.956533 
      545       546       547       548       549       550       551       552 
-5.955170 -5.934219 -5.956664 -5.934773 -5.956171 -5.932241 -5.881143 -5.912269 
      553       554       555       556       557       558       559       560 
-5.947700 -5.912269 -5.912269 -5.912269 -5.958172 -5.958172 -6.220897 -6.079175 
      561       562       563       564       565       566       567       568 
-5.950990 -5.660833 -5.882268 -5.858466 -5.896968 -5.927434 -5.956826 -5.933082 
      569       570       571       572       573       574       575       576 
-5.947546 -5.979821 -6.308158 -6.308158 -6.308158 -5.616553 -5.917004 -5.803043 
      577       578       579       580       581       582       583       584 
-5.980196 -5.942278 -5.946882 -5.275283 -5.346144 -5.868090 -5.868090 -5.868090 
      585       586       587       588       589       590       591       592 
-5.957873 -5.937729 -5.958069 -5.958069 -5.958069 -5.958069 -5.958069 -5.958069 
      593       594       595       596       597       598       599       600 
-5.958069 -5.958069 -5.955319 -5.955524 -5.328694 -5.364124 -5.956353 -5.949847 
      601       602       603       604       605       606       607       608 
-5.949847 -5.949847 -5.949847 -5.985278 -5.949847 -5.949847 -5.949847 -5.949847 
      609       610       611       612       613       614       615       616 
-5.949847 -5.984270 -5.942979 -5.942979 -5.720713 -5.720713 -5.945653 -4.100995 
      617       618       619       620       621       622       623       624 
-5.992047 -6.017695 -5.932221 -5.946962  5.688571 -6.039653 -6.039653 -6.039653 
      625       626       627       628       629       630       631       632 
-6.039653 -6.039653 -5.944389 -5.957904 -5.957904 -5.957614 -5.925608 -5.957617 
      633       634       635       636       637       638       639       640 
-5.957492 -5.854088 -5.957277 -5.765698 -5.765698 -5.957607 -5.949712 -5.954662 
      641       642       643       644       645       646       647       648 
-5.934997 -5.929355 -4.908320 -4.908320 -5.946964 -5.928494 -5.804046 -5.804046 
      649       650       651       652       653       654       655       656 
-5.941677 -5.941677 -5.957582 -5.956577 -5.743009 -5.957957 -5.955593 -5.955792 
      657       658       659       660       661       662       663       664 
-5.922538 -5.956429 -5.900066 -6.847069 -5.947326 -5.897517 -5.897517 -5.897517 
      665       666       667       668       669       670       671       672 
-5.955378 -5.889429 -5.957266 -5.919812 -5.956002 -5.857648 -5.928509 -5.857648 
      673       674       675       676       677       678       679       680 
-5.857648 -5.939471 -5.956852 -5.937283 -5.951507 -5.957111 -5.956415 -5.943236 
      681       682       683       684       685       686       687       688 
-5.949932 -5.952020 -5.952020 -5.952020 -5.952020 -5.957522 -5.956347 -5.956623 
      689       690       691       692       693       694       695       696 
-5.961344 -5.936242 -5.956632 -5.953222 -5.994717 -5.994717 -5.994717 -5.989553 
      697       698       699       700       701       702       703       704 
-5.989740 -5.955118 -5.964301 -5.964301 -5.952750 -5.927822 -5.966354 -5.606045 
      705       706       707       708       709       710       711       712 
-5.925105 -5.925105 -5.951885 -5.956655 -5.923506 -5.923506 -5.958936 -5.923506 
      713       714       715       716       717       718       719       720 
-5.958069 -5.955277 -5.894319 -5.894319 -5.932558 -5.911477 -5.934061 -5.932514 
      721       722       723       724       725       726       727       728 
-5.976505 -5.976505 -5.954465 -5.952266 -5.953019 -5.793099 -5.955714 -5.904413 
      729       730       731       732       733       734       735       736 
-5.904413 -5.727377 -5.953718 -5.944204 -5.928728 -5.958078 -5.940036 -5.950893 
      737       738       739       740       741       742       743       744 
-5.984690 -5.984690 -5.984690 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      745       746       747       748       749       750       751       752 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      753       754       755       756       757       758       759       760 
-6.108901 -6.108901 -6.108901 -6.108901 -6.144331 -6.108901 -6.108901 -6.108901 
      761       762       763       764       765       766       767       768 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      769       770       771       772       773       774       775       776 
-6.108901 -6.144331 -6.108901 -6.108901 -6.108901 -6.144331 -6.108901 -6.108901 
      777       778       779       780       781       782       783       784 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      785       786       787       788       789       790       791       792 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.144331 -6.108901 
      793       794       795       796       797       798       799       800 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      801       802       803       804       805       806       807       808 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      809       810       811       812       813       814       815       816 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      817       818       819       820       821       822       823       824 
-6.144331 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      825       826       827       828       829       830       831       832 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      833       834       835       836       837       838       839       840 
-6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 -6.108901 
      841       842       843       844       845       846       847       848 
-6.108901 -6.108901 -6.108901 -5.894620 -5.906009 -5.956038 -5.658228 -5.945691 
      849       850       851       852       853       854       855       856 
-5.954051 -5.954051 -5.989749 -5.940819 -5.930277 -5.930277 -5.958145 -5.985783 
      857       858       859       860       861       862       863       864 
-5.938140 -5.938140 -5.938140 -5.941720 -5.955907 -5.957772 -5.926572 -5.952691 
      865       866       867       868       869       870       871       872 
-5.952458 -5.952458 -5.952458 -5.952458 -5.938822 -5.934137 -5.956028 -5.947754 
      873       874       875       876       877       878       879       880 
-5.862834 -5.934090 -5.957384 -5.956838 -5.956838 -5.956887 -5.943533 -5.303792 
      881       882       883       884       885       886       887       888 
-5.956051 -5.818826 -5.963451 -5.909593 -5.946681 -5.946681 -5.946681 -5.946681 
      889       890       891       892       893       894       895       896 
-5.946681 -5.946681 -5.946681 -5.946681 -5.951323 -5.828736 -5.847411 -5.847411 
      897       898       899       900       901       902       903       904 
-5.890801 -6.037874 -5.980672 -5.946939 -5.931390 -5.916758 -5.804177 -5.875038 
      905       906       907       908       909       910       911       912 
-5.942336 -5.248645 -5.901280 -5.943231 -5.955871 -5.945215 -5.952460 -5.952460 
      913       914       915       916       917       918       919       920 
-5.952460 -5.735118 -5.951025 -5.951025 -5.951025 -5.261906 -5.913520 -5.949896 
      921       922       923       924       925       926       927       928 
-5.790859 -5.947630 -5.905502 -5.991907 -5.991907 -5.958769 -5.993147 -5.942291 
      929       930       931       932       933       934       935       936 
-5.957230 -5.957230 -5.957230 -5.957230 -5.957230 -5.940413 -5.957503 -5.964642 
      937       938       939       940       941       942       943       944 
-5.949947 -5.927961 -5.927961 -5.952612 -5.958362 -5.958050 -5.958050 -5.958050 
      945       946       947       948       949       950       951       952 
-5.958050 -5.958050 -5.958050 -5.941876 -5.786402 -5.936487 -5.954817 -5.924711 
      953       954       955       956       957       958       959       960 
-5.955158 -5.955788 -5.947880 -4.798623 -5.991664 -5.775194 -5.957300 -5.956497 
      961       962       963       964       965       966       967       968 
-5.951127 -5.932167 -5.965483 -5.957091 -5.952883 -5.941966 -5.954919 -5.918806 
      969       970       971       972       973       974       975       976 
-5.949699 -5.956724 -5.953782 -5.955969 -5.944954 -5.954788 -5.956863 -5.957816 
      977       978       979       980       981       982       983       984 
-5.971493 -5.971493 -5.971493 -5.971493 -5.971493 -5.971493 -5.971493 -5.971493 
      985       986       987       988       989       990       991       992 
-5.971493 -6.006924 -5.971493 -5.971493 -5.971493 -5.971493 -5.971493 -5.971493 
      993       994       995       996       997       998       999      1000 
-5.971493 -5.971493 -5.971493 -5.971493 -5.971493 -5.971493 -5.971493 -5.971493 
 [ reached getOption("max.print") -- omitted 1210 entries ]
Clustering
# Set random Seed
set.seed(123)
#Extract Data for clustering
Data_Cluster<-data.frame(Number_of_retweets=bitcoin4$retweet_count , Number_of_friends=bitcoin4$friends_count)
head(Data_Cluster)
 
 
Number_of_retweets
<dbl>
Number_of_friends
<dbl>
1	0	2382
2	2	2382
3	1	2382
4	0	2382
5	0	2382
6	1	2382
6 rows
##Within sum of squares
# For each K, perform wss, store the value
wss<-numeric(50)
for(k in 1:50) {
  wss[k] <- sum(kmeans(Data_Cluster,k,nstart=25)$withinss)
}
wss
 [1] 732220119653 145632562905  48633709843  41429491202  39264520509  38671837571
 [7]  38481110429  38383030199   7948678282   7924176162   6360863379   6247777829
[13]   6226572636   6217162761   6214192912   6211936716   6199352493   6195991668
[19]   2174171635   6193715609   6186207401   6188968357   5989156765   5969956437
[25]   6182960921   5988129154   5965340543   5868382562   2153819647   5981203410
[31]   5963920070   5972092918   5964621097   2148924839   5820127777   5924012508
[37]   2143193513   2143655973   5922924453   1939219459   5921014708   5920002998
[43]   2144082898   2137042105   1944573414   2136280839   5918348322   5911151913
[49]   5909318229   1937118925
# Make a data frame out of the wss result 
wssresult1<-data.frame(k=c(1:50),wss=wss)
wssresult1
k
<int>
wss
<dbl>
1	732220119653
2	145632562905
3	48633709843
4	41429491202
5	39264520509
6	38671837571
7	38481110429
8	38383030199
9	7948678282
10	7924176162
1-10 of 50 rows
#visualize wss
ggplot(data=wssresult1, mapping=aes(x= k, y= wss))+
       geom_line()+
         geom_point()+
           labs(title = "K-Means: Number of rtweets and friends ", x="Number of clusters", y="Within sum of squares")


1-Identify ideal k
Print<-"The ideal K would be 3"
Print
[1] "The ideal K would be 3"
2-Output ideal kâ€™s WSS value
Print<- "The ideal k's wss value is : 48633709843"
Print
[1] "The ideal k's wss value is : 48633709843"
3-Display the number of members per cluster
# Perform Kmeans with k set of 3
DataCluster<-kmeans(Data_Cluster, centers = 3, nstart = 25)
DataCluster
K-means clustering with 3 clusters of sizes 297, 9686, 17

Cluster means:
  Number_of_retweets Number_of_friends
1          0.4410774         19203.579
2          0.9768738           533.144
3          1.0588235        186454.647

Clustering vector:
   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [40] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [79] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [118] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [157] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [196] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [235] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [274] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [313] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [352] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [391] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [430] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [469] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [508] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [547] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [586] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [625] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2
 [664] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [703] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [742] 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [781] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [820] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [859] 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [898] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [937] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [976] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [ reached getOption("max.print") -- omitted 9000 entries ]

Within cluster sum of squares by cluster:
[1] 25527650590  9716669703 13389389551
 (between_SS / total_SS =  93.4 %)

Available components:

[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
[6] "betweenss"    "size"         "iter"         "ifault"      
3-For each data set, graph the ideal kâ€™s clusters
# Add the clusters assignment to each point
Data_Cluster$Cluster<-as.factor(DataCluster$cluster)
# Get centroids
centroids1<-as.data.frame(DataCluster$centers)
centroids1$Cluster<-as.factor(c(1:3))
## Visualize cluster assignment

bit<- head(Data_Cluster,50)
ggplot(data = bit, mapping = aes(retweet_count, friends_count , color= blues9))+
  geom_point(data=centroids1, mapping = aes(x= retweet_count, y=friends_count, fill= red), size=5, shape=13) +
  labs(title= "Number of rtweets and friends", x="Number of retweets" , y= "Number of friends")
